{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "from ndlib.viz.mpl.DiffusionTrend import DiffusionTrend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_mean(data):\n",
    "    return np.mean(list(data.values()))\n",
    "\n",
    "def give_properties(G):\n",
    "    clustering_coefficient = give_mean(nx.clustering(G, nodes=None, weight=None))\n",
    "    closeness_centrality = give_mean(nx.closeness_centrality(G, u=None, distance=None, wf_improved=True))\n",
    "    betweenness_centrality = give_mean(nx.betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None))\n",
    "    degree_centrality = give_mean(nx.degree_centrality(G))\n",
    "\n",
    "    properties = np.matrix([clustering_coefficient, closeness_centrality, betweenness_centrality, degree_centrality])\n",
    "\n",
    "    return(properties)\n",
    "\n",
    "def evaluate(beta, gamma, I, n_iterations, G):\n",
    "    \"\"\"\n",
    "    This function evaluates the spread of disease following the SIR model using the NDlib package \n",
    "    (https://ndlib.readthedocs.io/en/latest/index.html). It first implements the SIR model on the given network G. Next,\n",
    "    the model parameters beta, gamma, and the number of initial infections is set for the model. The returned dictionairy trends gives the \n",
    "    amount of nodes in each state and the rate of change for each state. \n",
    "    \"\"\"\n",
    "    model = ep.SIRModel(G)\n",
    "\n",
    "    # Setting model parameters\n",
    "    cfg = mc.Configuration()\n",
    "    cfg.add_model_parameter('beta', beta)\n",
    "    cfg.add_model_parameter('gamma', gamma)\n",
    "    cfg.add_model_parameter(\"fraction_infected\", I)\n",
    "\n",
    "    model.set_initial_status(cfg)\n",
    "\n",
    "    # Running the simulation\n",
    "    iterations = model.iteration_bunch(n_iterations)\n",
    "    trends = model.build_trends(iterations)\n",
    "\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3σ for n=50 nodes\n",
      "                   clustering_coefficient    closeness_centrality    betweenness_centrality    degree_centrality\n",
      "---------------  ------------------------  ----------------------  ------------------------  -------------------\n",
      "barabasi-albert                 0.187016                0.0332018                0.00469626          8.10301e-17\n",
      "watts-strogatz                  0.121034                0.0640531                0.0225923           4.16334e-17\n",
      "erdos-renyi                     0.0828191               0.0600728                0.00766563          0.0248683\n",
      "\n",
      " 3σ for n=100 nodes\n",
      "                   clustering_coefficient    closeness_centrality    betweenness_centrality    degree_centrality\n",
      "---------------  ------------------------  ----------------------  ------------------------  -------------------\n",
      "barabasi-albert                 0.0605914               0.0103555               0.000508693          2.42405e-17\n",
      "watts-strogatz                  0.0646079               0.0248712               0.0019135            4.57399e-17\n",
      "erdos-renyi                     0.0267904               0.0208049               0.00107594           0.0122543\n",
      "\n",
      " 3σ for n=200 nodes\n",
      "                   clustering_coefficient    closeness_centrality    betweenness_centrality    degree_centrality\n",
      "---------------  ------------------------  ----------------------  ------------------------  -------------------\n",
      "barabasi-albert                 0.0241605              0.00458215               0.000100354          5.75234e-17\n",
      "watts-strogatz                  0.0338071              0.00872926               0.000259734          1.4362e-17\n",
      "erdos-renyi                     0.0103601              0.00924498               0.000194146          0.00625897\n"
     ]
    }
   ],
   "source": [
    "# Generate Networks of equivalent Form\n",
    "p = 0.1\n",
    "runs=1000\n",
    "\n",
    "def give_networks(n):\n",
    "    k = int(p*n)\n",
    "    m = int(k/2)\n",
    "\n",
    "    properties_er, properties_ws, properties_ba = np.zeros((4,runs)), np.zeros((4,runs)), np.zeros((4,runs))\n",
    "    er_list, ws_list, ba_list = [], [], []\n",
    "\n",
    "    for i in range(0, runs):\n",
    "        seed=int(i)\n",
    "        er = nx.erdos_renyi_graph(n, p, seed)   \n",
    "        properties_er[:,i] = give_properties(er)\n",
    "        er_list.append(er)\n",
    "        \n",
    "    for i in range(0, runs):\n",
    "        seed=int(i)\n",
    "        ws = nx.watts_strogatz_graph(n, k, p, seed)\n",
    "        properties_ws[:,i] = give_properties(ws)\n",
    "        ws_list.append(ws)\n",
    "\n",
    "    for i in range(0, runs):\n",
    "        seed=int(i)\n",
    "        ba = nx.barabasi_albert_graph(n, m, seed)\n",
    "        properties_ba[:,i] = give_properties(ba)\n",
    "        ba_list.append(ba)\n",
    "\n",
    "    table_sd = [['barabasi-albert', 3*np.std(properties_ba[0,:]), 3*np.std(properties_ba[1,:]), 3*np.std(properties_ba[2,:]), 3*np.std(properties_ba[3,:])],\n",
    "            ['watts-strogatz', 3*np.std(properties_ws[0,:]), 3*np.std(properties_ws[1,:]), 3*np.std(properties_ws[2,:]), 3*np.std(properties_ws[3,:])], \n",
    "            ['erdos-renyi', 3*np.std(properties_er[0,:]), 3*np.std(properties_er[1,:]), 3*np.std(properties_er[2,:]), 3*np.std(properties_er[3,:])]]\n",
    "\n",
    "    table = [['barabasi-albert', np.mean(properties_ba[0,:]), np.mean(properties_ba[1,:]), np.mean(properties_ba[2,:]), np.mean(properties_ba[3,:])],\n",
    "            ['watts-strogatz', np.mean(properties_ws[0,:]), np.mean(properties_ws[1,:]), np.mean(properties_ws[2,:]), np.mean(properties_ws[3,:])], \n",
    "            ['erdos-renyi', np.mean(properties_er[0,:]), np.mean(properties_er[1,:]), np.mean(properties_er[2,:]), np.mean(properties_er[3,:])]]\n",
    "\n",
    "    print(f'\\n 3\\u03C3 for n={n} nodes')\n",
    "    print(tabulate(table_sd, headers=['clustering_coefficient', 'closeness_centrality', 'betweenness_centrality', 'degree_centrality']))\n",
    "\n",
    "    # print(f'\\n properties for n={n} nodes')\n",
    "    # print(tabulate(table, headers=['clustering_coefficient', 'closeness_centrality', 'betweenness_centrality', 'degree_centrality']))\n",
    "\n",
    "    return (er_list, ws_list, ba_list)\n",
    "\n",
    "er_list_50, ws_list_50, ba_list_50 = give_networks(50)\n",
    "er_list, ws_list, ba_list = give_networks(100) ### Saving for next experiment\n",
    "er_list_200, ws_list_200, ba_list_200 = give_networks(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate SIR spread on the network\n",
    "plt.clf()\n",
    "beta_list =  [1, 1/3, 1/6] \n",
    "gamma = 1/3\n",
    "I0 = 0.01\n",
    "n_iterations = 30\n",
    "n=100\n",
    "\n",
    "for beta in beta_list:\n",
    "    er_X, er_Y, er_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "    ws_X, ws_Y, ws_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "    ba_X, ba_Y, ba_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "\n",
    "    for i in range(n):\n",
    "        er = er_list[i]\n",
    "        ws = ws_list[i]\n",
    "        ba = ba_list[i]\n",
    "\n",
    "        trends_er = evaluate(beta, gamma, I0, n_iterations, er)\n",
    "        trends_ws = evaluate(beta, gamma, I0, n_iterations, ws)\n",
    "        trends_ba = evaluate(beta, gamma, I0, n_iterations, ba)\n",
    "\n",
    "        # Add values of next network evaluation\n",
    "        er_X = np.add(er_X, trends_er[0]['trends']['node_count'][0])\n",
    "        er_Y = np.add(er_Y, trends_er[0]['trends']['node_count'][1])\n",
    "        er_Z = np.add(er_Z, trends_er[0]['trends']['node_count'][2])\n",
    "\n",
    "        ws_X = np.add(ws_X, trends_ws[0]['trends']['node_count'][0]) \n",
    "        ws_Y = np.add(ws_Y, trends_ws[0]['trends']['node_count'][1]) \n",
    "        ws_Z = np.add(ws_Z, trends_ws[0]['trends']['node_count'][2]) \n",
    "\n",
    "        ba_X = np.add(ba_X, trends_ba[0]['trends']['node_count'][0]) \n",
    "        ba_Y = np.add(ba_Y, trends_ba[0]['trends']['node_count'][1]) \n",
    "        ba_Z = np.add(ba_Z, trends_ba[0]['trends']['node_count'][2]) \n",
    "\n",
    "    er_I = er_Y/(runs*n)\n",
    "    ws_I = ws_Y/(runs*n)\n",
    "    ba_I = ba_Y/(runs*n)\n",
    "\n",
    "    plt.figure(figsize=(10,6), tight_layout=True)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    \n",
    "    plt.plot(er_I, label=\"Erd\\u0151s-R\\u00e9nyi\", linewidth=2)\n",
    "    plt.plot(ws_I, label=\"Watts-Strogatz\", linewidth=2)\n",
    "    plt.plot(ba_I, label=\"Barab\\u00e1si-Albert\", linewidth=2)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel('t', fontsize = 25)\n",
    "    plt.ylabel('I', fontsize = 25)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.title(f'Fraction of infected hosts over time, \\u03B2={np.round(beta,2)}', fontsize=25)\n",
    "    plt.legend(fontsize = 24)\n",
    "\n",
    "    plt.savefig(f'plots2/beta-{np.round(beta,2)}_gamma-{np.round(gamma,2)}_I0-{I0}.png')\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic vaccination campaign\n",
    "\n",
    "def evaluate_vacc_step(beta, gamma, infected_nodes_initial, n_iterations, G, test_accuracy=1, tests_used=0, n_vacc=0, test_max=200):\n",
    "    infected_nodes = infected_nodes_initial\n",
    "    model = ep.SIRModel(G) \n",
    "\n",
    "    if len(infected_nodes) != 0 and tests_used < test_max:\n",
    "        for _ in range(n_vacc):\n",
    "            closeness_centrality = nx.closeness_centrality(G)\n",
    "            closeness_centrality_values = list(closeness_centrality.values())\n",
    "            closeness_centrality_ordered = sorted(list(closeness_centrality.values()), reverse=True)\n",
    "\n",
    "            infected = True\n",
    "            next_max = 0\n",
    "\n",
    "            while infected == True and next_max < len(closeness_centrality_ordered):\n",
    "                accuracy = np.random.binomial(1, test_accuracy)\n",
    "                target_index = closeness_centrality_values.index(closeness_centrality_ordered[next_max])\n",
    "                target_node = list(closeness_centrality.keys())[target_index]\n",
    "                tests_used += 1\n",
    "                next_max += 1\n",
    "\n",
    "                if target_node in infected_nodes and accuracy == 0:\n",
    "                    infected = False\n",
    "                \n",
    "                if target_node not in infected_nodes and accuracy == 1 and tests_used < test_max:\n",
    "                    G.remove_node(target_node)\n",
    "                    infected = False\n",
    "                \n",
    "    for _ in range(n_iterations):\n",
    "\n",
    "        recovered_nodes = []\n",
    "        \n",
    "        # Model Configuration\n",
    "        cfg = mc.Configuration()\n",
    "        cfg.add_model_parameter('beta', beta)\n",
    "        cfg.add_model_parameter('gamma', gamma)\n",
    "        cfg.add_model_initial_configuration(\"Infected\", infected_nodes)\n",
    "\n",
    "\n",
    "        model.set_initial_status(cfg)\n",
    "\n",
    "        # Simulation execution\n",
    "        iterations = model.iteration_bunch(1)\n",
    "        trends = model.build_trends(iterations)\n",
    "\n",
    "        # Find direct neighbors of infected nodes\n",
    "        neighbors_infected_nodes = []\n",
    "        for node in infected_nodes:\n",
    "            # print(node)\n",
    "        \n",
    "            for neighbor_node in G.neighbors(node):\n",
    "                neighbors_infected_nodes.append(neighbor_node)\n",
    "\n",
    "            # remove neighbor if neighbor already infected\n",
    "            overlap = np.intersect1d(neighbors_infected_nodes, infected_nodes)\n",
    "            for node in overlap:\n",
    "                neighbors_infected_nodes.remove(node)\n",
    "            \n",
    "            # only have each neighbour once, even if it is shared by multiple nodes\n",
    "            neighbors_infected_nodes = list(np.unique(neighbors_infected_nodes))\n",
    "\n",
    "        number_of_infections = trends[0]['trends']['status_delta'][1][0]\n",
    "\n",
    "        \n",
    "        if number_of_infections > 0:\n",
    "            \"\"\"Random neighbors of the infected nodes are now infected, if the simulation asks for more infections than\n",
    "            there are direct neighbors all direct neuighbors will be infected\"\"\"\n",
    "            if len(neighbors_infected_nodes) > number_of_infections:\n",
    "                added_infections = np.random.choice(neighbors_infected_nodes, number_of_infections, replace=False)\n",
    "            else:\n",
    "                added_infections = np.random.choice(neighbors_infected_nodes, len(neighbors_infected_nodes), replace=False)\n",
    "            \n",
    "            infected_nodes.extend(added_infections)\n",
    "        \n",
    "        if number_of_infections < 0:\n",
    "            \"\"\"Random infected nodes are now recovered, if the simulation asks for more recovering infected hosts than\n",
    "            there are infected hosts all infected hosts will recover\"\"\"\n",
    "            if len(infected_nodes) > np.abs(number_of_infections):\n",
    "                removed_infections = np.random.choice(infected_nodes, np.abs(number_of_infections), replace=False)\n",
    "            else:\n",
    "                removed_infections = np.random.choice(infected_nodes, len(infected_nodes), replace=False)\n",
    "\n",
    "            for removed_infection in removed_infections:\n",
    "                infected_nodes.remove(removed_infection)\n",
    "                G.remove_node(removed_infection)\n",
    "                recovered_nodes.append(removed_infection)\n",
    "\n",
    "    return G, infected_nodes, recovered_nodes, tests_used\n",
    "    \n",
    "\n",
    "\"Creating edgelist\"\n",
    "data = np.loadtxt(open(\"transmission_network.csv\", \"rb\"), delimiter=\";\", skiprows=1)[:, 1:]\n",
    "nonzero_x = np.nonzero(data)[0]\n",
    "nonzero_y = np.nonzero(data)[1]\n",
    "\n",
    "edges=[]\n",
    "for i in range(len(nonzero_x)):\n",
    "    edges.append((nonzero_x[i], nonzero_y[i]))\n",
    "\n",
    "\"Set parameters\"\n",
    "beta =  1\n",
    "gamma = 1/3\n",
    "n_iterations = 2\n",
    "n_vacc_list = [1,3,5,10]\n",
    "test_accuracy_list=[0.25,0.5,1]\n",
    "\n",
    "n_samples=1000\n",
    "end_time={}\n",
    "end_time_std={}\n",
    "max_infected={}\n",
    "max_infected_std={}\n",
    "\n",
    "for test_accuracy in test_accuracy_list:\n",
    "    for n_vacc in n_vacc_list:\n",
    "        end_time_list = []\n",
    "        max_infected_list = []\n",
    "        for _ in range(n_samples):\n",
    "            G = nx.from_edgelist(edges)\n",
    "            infected_nodes =  list(np.random.choice(list(G.nodes), 5, replace=False))\n",
    "            tests_used = 0\n",
    "            t = -1 ### Start at t=0\n",
    "            test_max = 0\n",
    "            max_infected_nodes = 0\n",
    "            while len(infected_nodes) != 0:\n",
    "                t+=1\n",
    "                G_new, infected_nodes_new, recovered_nodes, tests_used_new = evaluate_vacc_step(beta, gamma, infected_nodes, n_iterations, G, test_accuracy, tests_used, n_vacc, test_max)\n",
    "                G=G_new\n",
    "                infected_nodes=infected_nodes\n",
    "                tests_used = tests_used_new\n",
    "\n",
    "                if len(infected_nodes) > max_infected_nodes:\n",
    "                    max_infected_nodes = len(infected_nodes)\n",
    "\n",
    "            end_time_list.append(t)\n",
    "            max_infected_list.append(max_infected_nodes)\n",
    "\n",
    "        end_time[test_accuracy, n_vacc] = np.mean(end_time_list)\n",
    "        max_infected[test_accuracy, n_vacc] = np.mean(max_infected_list)\n",
    "\n",
    "        end_time_std[test_accuracy, n_vacc] = np.std(end_time_list)\n",
    "        max_infected_std[test_accuracy, n_vacc] = np.std(max_infected_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time until the disease passes 74.163 31.072880120774126\n",
      "Average maximum number of infected hosts 267.11 18.724398521714924\n"
     ]
    }
   ],
   "source": [
    "### Final run for the case of no infecteds \n",
    "\n",
    "end_time_value_list = []\n",
    "max_infected_nodes_list = []\n",
    "for _ in range(n_samples):\n",
    "    G = nx.from_edgelist(edges)\n",
    "    infected_nodes =  list(np.random.choice(list(G.nodes), 5, replace=False))\n",
    "    tests_used = 0\n",
    "    t = -1 ### Start at t=0\n",
    "    test_max = 0\n",
    "    max_infected_nodes = 0\n",
    "    while len(infected_nodes) != 0:\n",
    "        t+=1\n",
    "        G_new, infected_nodes_new, recovered_nodes, tests_used_new = evaluate_vacc_step(beta, gamma, infected_nodes, n_iterations, G, test_accuracy, tests_used, n_vacc, test_max)\n",
    "        G=G_new\n",
    "        infected_nodes=infected_nodes\n",
    "        tests_used = tests_used_new\n",
    "\n",
    "        if len(infected_nodes) > max_infected_nodes:\n",
    "            max_infected_nodes = len(infected_nodes)\n",
    "\n",
    "    end_time_value_list.append(t)\n",
    "    max_infected_nodes_list.append(max_infected_nodes)\n",
    "\n",
    "print('Average time until the disease passes', np.mean(end_time_value_list), 3*np.std(end_time_value_list))\n",
    "print('Average maximum number of infected hosts', np.mean(max_infected_nodes_list), 3*np.std(max_infected_nodes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time until the disease passes\n",
      "           1       3       5      10\n",
      "----  ------  ------  ------  ------\n",
      "0.25  73.938  75.51   74.354  74.381\n",
      "0.5   74.574  73.863  74.287  73.899\n",
      "1     74.742  74.481  74.833  74.4\n",
      "3σ on endtime\n",
      "            1        3        5       10\n",
      "----  -------  -------  -------  -------\n",
      "0.25  31.2245  29.6144  30.8012  30.5632\n",
      "0.5   30.1052  29.0186  30.142   29.6983\n",
      "1     30.6851  31.2256  31.4083  29.9417\n"
     ]
    }
   ],
   "source": [
    "table = [[test_accuracy_list[0], end_time[test_accuracy_list[0], n_vacc_list[0]], end_time[test_accuracy_list[0], n_vacc_list[1]], end_time[test_accuracy_list[0], n_vacc_list[2]], end_time[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], end_time[test_accuracy_list[1], n_vacc_list[0]], end_time[test_accuracy_list[1], n_vacc_list[1]], end_time[test_accuracy_list[1], n_vacc_list[2]], end_time[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], end_time[test_accuracy_list[2], n_vacc_list[0]],end_time[test_accuracy_list[2], n_vacc_list[1]], end_time[test_accuracy_list[2], n_vacc_list[2]], end_time[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "table_std = [[test_accuracy_list[0], 3*end_time_std[test_accuracy_list[0], n_vacc_list[0]], 3*end_time_std[test_accuracy_list[0], n_vacc_list[1]], 3*end_time_std[test_accuracy_list[0], n_vacc_list[2]], 3*end_time_std[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], 3*end_time_std[test_accuracy_list[1], n_vacc_list[0]], 3*end_time_std[test_accuracy_list[1], n_vacc_list[1]], 3*end_time_std[test_accuracy_list[1], n_vacc_list[2]], 3*end_time_std[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], 3*end_time_std[test_accuracy_list[2], n_vacc_list[0]],3*end_time_std[test_accuracy_list[2], n_vacc_list[1]], 3*end_time_std[test_accuracy_list[2], n_vacc_list[2]], 3*end_time_std[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "print('Average time until the disease passes')\n",
    "print(tabulate(table, headers=n_vacc_list))\n",
    "\n",
    "print('3\\u03C3 on endtime')\n",
    "print(tabulate(table_std, headers=n_vacc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average maximum number of infected hosts\n",
      "           1       3       5      10\n",
      "----  ------  ------  ------  ------\n",
      "0.25  267.23  266.81  267.45  266.53\n",
      "0.5   266.83  266.8   266.61  266.58\n",
      "1     266.56  267.24  265.74  266.74\n",
      "3σ on max infected\n",
      "            1        3        5       10\n",
      "----  -------  -------  -------  -------\n",
      "0.25  19.7219  19.6755  18.0219  21.7265\n",
      "0.5   18.6099  19.5668  16.9275  16.6557\n",
      "1     17.0833  17.9305  17.8978  17.7615\n"
     ]
    }
   ],
   "source": [
    "table = [[test_accuracy_list[0], max_infected[test_accuracy_list[0], n_vacc_list[0]], max_infected[test_accuracy_list[0], n_vacc_list[1]], max_infected[test_accuracy_list[0], n_vacc_list[2]], max_infected[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], max_infected[test_accuracy_list[1], n_vacc_list[0]], max_infected[test_accuracy_list[1], n_vacc_list[1]], max_infected[test_accuracy_list[1], n_vacc_list[2]], max_infected[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], max_infected[test_accuracy_list[2], n_vacc_list[0]],max_infected[test_accuracy_list[2], n_vacc_list[1]], max_infected[test_accuracy_list[2], n_vacc_list[2]], max_infected[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "table_std = [[test_accuracy_list[0], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[0]], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[1]], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[2]], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[0]], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[1]], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[2]], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[0]], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[1]], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[2]], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "print('Average maximum number of infected hosts')\n",
    "print(tabulate(table, headers=n_vacc_list))\n",
    "\n",
    "print('3\\u03C3 on max infected')\n",
    "print(tabulate(table_std, headers=n_vacc_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
