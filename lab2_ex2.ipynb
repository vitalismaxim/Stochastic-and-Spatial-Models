{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "from ndlib.viz.mpl.DiffusionTrend import DiffusionTrend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### CITE NETWORKX AND NDLIB !!!!!\n",
    "def give_mean(data):\n",
    "    return np.mean(list(data.values()))\n",
    "\n",
    "def give_properties(G):\n",
    "    # Model properties\n",
    "    clustering_coefficient = give_mean(nx.clustering(G, nodes=None, weight=None))\n",
    "    closeness_centrality = give_mean(nx.closeness_centrality(G, u=None, distance=None, wf_improved=True))\n",
    "    betweenness_centrality = give_mean(nx.betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None))\n",
    "    degree_centrality = give_mean(nx.degree_centrality(G))\n",
    "    average_shortest_path_length = nx.average_shortest_path_length(G, weight=None, method=None)\n",
    "\n",
    "    properties = np.matrix([clustering_coefficient, closeness_centrality, betweenness_centrality, degree_centrality, average_shortest_path_length])\n",
    "\n",
    "    return(properties)\n",
    "\n",
    "def evaluate(beta, gamma, I, n_iterations, G, export_name=\"untitled.pdf\", vis=False):\n",
    "    # Model selection\n",
    "    model = ep.SIRModel(G)\n",
    "\n",
    "    # Model Configuration\n",
    "    cfg = mc.Configuration()\n",
    "    cfg.add_model_parameter('beta', beta)\n",
    "    cfg.add_model_parameter('gamma', gamma)\n",
    "    cfg.add_model_parameter(\"fraction_infected\", I)\n",
    "    model.set_initial_status(cfg)\n",
    "\n",
    "    # Simulation execution\n",
    "    iterations = model.iteration_bunch(n_iterations)\n",
    "    trends = model.build_trends(iterations)\n",
    "\n",
    "    # Visualization\n",
    "    if vis == True:\n",
    "        viz = DiffusionTrend(model, trends)\n",
    "        viz.plot(export_name)\n",
    "\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "done2\n"
     ]
    }
   ],
   "source": [
    "# Generate Networks of equivalent Form\n",
    "n = 100\n",
    "p = 0.1\n",
    "k = int(n * p)\n",
    "m = int(n * p)\n",
    "\n",
    "runs=10\n",
    "properties_er, properties_ws, properties_ba = np.zeros((5,runs)), np.zeros((5,runs)), np.zeros((5,runs))\n",
    "er_list, ws_list, ba_list = [], [], []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    seed=int(i)\n",
    "    er = nx.erdos_renyi_graph(n, p, seed)   \n",
    "    properties_er[:,i] = give_properties(er)\n",
    "    er_list.append(er)\n",
    "    \n",
    "print('done1')\n",
    "for i in range(0, runs):\n",
    "    seed=int(i)\n",
    "    ws = nx.watts_strogatz_graph(n, k, p, seed)\n",
    "    properties_ws[:,i] = give_properties(ws)\n",
    "    ws_list.append(ws)\n",
    "\n",
    "print('done2')\n",
    "for i in range(0, runs):\n",
    "    seed=int(i)\n",
    "    ba = nx.barabasi_albert_graph(n, m, seed)\n",
    "    properties_ba[:,i] = give_properties(ba)\n",
    "    ba_list.append(ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_string = [\"clustering_coefficient\", \"closeness_centrality\", \"betweenness_centrality\", \"degree_centrality\", \"average_shortest_path_length\"]\n",
    "\n",
    "plt.hist(properties_er[0,:])\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennadevries/anaconda3/lib/python3.10/site-packages/ndlib/models/DiffusionModel.py:169: UserWarning: The fraction_infected value is too low given the number of nodes of the selected graph: a single node will be set as infected\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Simulate SIR spread on the network\n",
    "plt.clf()\n",
    "beta_list =  [1, 1/3, 1/6] \n",
    "gamma = 1/3\n",
    "I0_list = [0.001, 0.01, 0.1]\n",
    "n_iterations = 50\n",
    "\n",
    "for I0 in I0_list:\n",
    "    for beta in beta_list:\n",
    "        er_X, er_Y, er_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "        ws_X, ws_Y, ws_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "        ba_X, ba_Y, ba_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "\n",
    "        for i in range(len(er_list)):\n",
    "            er = er_list[i]\n",
    "            ws = ws_list[i]\n",
    "            ba = ba_list[i]\n",
    "\n",
    "            trends_er = evaluate(beta, gamma, I0, n_iterations, er)\n",
    "            trends_ws = evaluate(beta, gamma, I0, n_iterations, ws)\n",
    "            trends_ba = evaluate(beta, gamma, I0, n_iterations, ba)\n",
    "\n",
    "            er_X = np.add(er_X, trends_er[0]['trends']['node_count'][0])\n",
    "            er_Y = np.add(er_Y, trends_er[0]['trends']['node_count'][1])\n",
    "            er_Z = np.add(er_Z, trends_er[0]['trends']['node_count'][2])\n",
    "\n",
    "            ws_X = np.add(ws_X, trends_ws[0]['trends']['node_count'][0]) \n",
    "            ws_Y = np.add(ws_Y, trends_ws[0]['trends']['node_count'][1]) \n",
    "            ws_Z = np.add(ws_Z, trends_ws[0]['trends']['node_count'][2]) \n",
    "\n",
    "            ba_X = np.add(ba_X, trends_ba[0]['trends']['node_count'][0]) \n",
    "            ba_Y = np.add(ba_Y, trends_ba[0]['trends']['node_count'][1]) \n",
    "            ba_Z = np.add(ba_Z, trends_ba[0]['trends']['node_count'][2]) \n",
    "\n",
    "        plt.ylim(0,1)\n",
    "        plt.plot(er_Y/(runs*n))\n",
    "        plot_string = 'plots2/er_beta-' + str(np.round(beta,2)) + '_gamma-' + str(np.round(gamma,2)) + '_I0-' + str(I0) + '.png'\n",
    "        plt.savefig(plot_string)\n",
    "        plt.clf()\n",
    "\n",
    "        plt.ylim(0,1)\n",
    "        plt.plot(ws_Y/(runs*n))\n",
    "        plot_string = 'plots2/ws_beta-' + str(np.round(beta,2)) + '_gamma-' + str(np.round(gamma,2)) + '_I0-' + str(I0) + '.png'\n",
    "        plt.savefig(plot_string)\n",
    "        plt.clf()\n",
    "\n",
    "        plt.ylim(0,1)\n",
    "        plt.plot(ba_Y/(runs*n))\n",
    "        plot_string = 'plots2/ba_beta-' + str(np.round(beta,2)) + '_gamma-' + str(np.round(gamma,2)) + '_I0-' + str(I0) + '.png'\n",
    "        plt.savefig(plot_string)\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic vaccination campaign\n",
    "plt.clf()\n",
    "data = open(\"transmission_network.csv\")\n",
    "read = csv.reader(data)\n",
    "\n",
    "beta_list =  1\n",
    "gamma = 1/3\n",
    "I0 = 5/374\n",
    "n_iterations = 50\n",
    "\n",
    "X, Y, Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "\n",
    "for i in range(len(er_list)):\n",
    "    er = er_list[i]\n",
    "    ws = ws_list[i]\n",
    "    ba = ba_list[i]\n",
    "\n",
    "    trends = evaluate(beta, gamma, I0, n_iterations, G)\n",
    "\n",
    "    X = np.add(er_X, trends_er[0]['trends']['node_count'][0])\n",
    "    Y = np.add(er_Y, trends_er[0]['trends']['node_count'][1])\n",
    "    Z = np.add(er_Z, trends_er[0]['trends']['node_count'][2])\n",
    "\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.plot(er_Y/(runs*n))\n",
    "plot_string = 'plots2/er_beta-' + str(np.round(beta,2)) + '_gamma-' + str(np.round(gamma,2)) + '_I0-' + str(I0) + '.png'\n",
    "plt.savefig(plot_string)\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[39m.\u001b[39mclf()\n\u001b[0;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mtransmission_network.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m), delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m edgelist \u001b[39m=\u001b[39m [(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m), (\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m), (\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m)]  \u001b[39m# single edge (0,1)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m G \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mfrom_edgelist(edgelist)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1017\u001b[0m         data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[1;32m   1018\u001b[0m         imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[1;32m   1019\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m   1020\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1021\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[1;32m   1022\u001b[0m         byte_converters\u001b[39m=\u001b[39;49mbyte_converters)\n\u001b[1;32m   1024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string '' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "plt.clf()\n",
    "data = np.loadtxt(open(\"transmission_network.csv\", \"rb\"), delimiter=\";\", skiprows=1)\n",
    "\n",
    "edgelist = [(0, 1), (0,2), (0,3)]  # single edge (0,1)\n",
    "G = nx.from_edgelist(edgelist)\n",
    "nx.draw(G)\n",
    "plt.savefig('test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
