{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "from ndlib.viz.mpl.DiffusionTrend import DiffusionTrend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_mean(data):\n",
    "    return np.mean(list(data.values()))\n",
    "\n",
    "def give_properties(G):\n",
    "    clustering_coefficient = give_mean(nx.clustering(G, nodes=None, weight=None))\n",
    "    closeness_centrality = give_mean(nx.closeness_centrality(G, u=None, distance=None, wf_improved=True))\n",
    "    betweenness_centrality = give_mean(nx.betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None))\n",
    "    degree_centrality = give_mean(nx.degree_centrality(G))\n",
    "\n",
    "    properties = np.matrix([clustering_coefficient, closeness_centrality, betweenness_centrality, degree_centrality])\n",
    "\n",
    "    return(properties)\n",
    "\n",
    "def evaluate(beta, gamma, I, n_iterations, G):\n",
    "    \"\"\"\n",
    "    This function evaluates the spread of disease following the SIR model using the NDlib package \n",
    "    (https://ndlib.readthedocs.io/en/latest/index.html). It first implements the SIR model on the given network G. Next,\n",
    "    the model parameters beta, gamma, and the number of initial infections is set for the model. The returned dictionairy trends gives the \n",
    "    amount of nodes in each state and the rate of change for each state. \n",
    "    \"\"\"\n",
    "    model = ep.SIRModel(G)\n",
    "\n",
    "    # Setting model parameters\n",
    "    cfg = mc.Configuration()\n",
    "    cfg.add_model_parameter('beta', beta)\n",
    "    cfg.add_model_parameter('gamma', gamma)\n",
    "    cfg.add_model_parameter(\"fraction_infected\", I)\n",
    "\n",
    "    model.set_initial_status(cfg)\n",
    "\n",
    "    # Running the simulation\n",
    "    iterations = model.iteration_bunch(n_iterations)\n",
    "    trends = model.build_trends(iterations)\n",
    "\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3σ for n=50 nodes\n",
      "                   clustering_coefficient    closeness_centrality    betweenness_centrality    degree_centrality\n",
      "---------------  ------------------------  ----------------------  ------------------------  -------------------\n",
      "barabasi-albert                0.00591397              0.00104993               0.000148509          2.53219e-18\n",
      "watts-strogatz                 0.00382742              0.00202554               0.000714431          1.9507e-18\n",
      "erdos-renyi                    0.00261897              0.00189967               0.000242409          0.000786405\n",
      "\n",
      " 3σ for n=100 nodes\n",
      "                   clustering_coefficient    closeness_centrality    betweenness_centrality    degree_centrality\n",
      "---------------  ------------------------  ----------------------  ------------------------  -------------------\n",
      "barabasi-albert               0.00191607              0.000327471               1.60863e-05          2.30362e-18\n",
      "watts-strogatz                0.00204308              0.000786498               6.05101e-05          1.80887e-18\n",
      "erdos-renyi                   0.000847188             0.000657907               3.40242e-05          0.000387515\n",
      "\n",
      " 3σ for n=200 nodes\n",
      "                   clustering_coefficient    closeness_centrality    betweenness_centrality    degree_centrality\n",
      "---------------  ------------------------  ----------------------  ------------------------  -------------------\n",
      "barabasi-albert               0.000764023             0.0001449                 3.17348e-06          1.79761e-18\n",
      "watts-strogatz                0.00106907              0.000276043               8.21351e-06          1.50887e-18\n",
      "erdos-renyi                   0.000327615             0.000292352               6.13945e-06          0.000197926\n"
     ]
    }
   ],
   "source": [
    "# Generate Networks of equivalent Form\n",
    "p = 0.1\n",
    "runs=1000\n",
    "\n",
    "def give_networks(n):\n",
    "    k = int(p*n)\n",
    "    m = int(k/2)\n",
    "\n",
    "    properties_er, properties_ws, properties_ba = np.zeros((4,runs)), np.zeros((4,runs)), np.zeros((4,runs))\n",
    "    er_list, ws_list, ba_list = [], [], []\n",
    "\n",
    "    for i in range(0, runs):\n",
    "        seed=int(i)\n",
    "        er = nx.erdos_renyi_graph(n, p, seed)   \n",
    "        properties_er[:,i] = give_properties(er)\n",
    "        er_list.append(er)\n",
    "        \n",
    "    for i in range(0, runs):\n",
    "        seed=int(i)\n",
    "        ws = nx.watts_strogatz_graph(n, k, p, seed)\n",
    "        properties_ws[:,i] = give_properties(ws)\n",
    "        ws_list.append(ws)\n",
    "\n",
    "    for i in range(0, runs):\n",
    "        seed=int(i)\n",
    "        ba = nx.barabasi_albert_graph(n, m, seed)\n",
    "        properties_ba[:,i] = give_properties(ba)\n",
    "        ba_list.append(ba)\n",
    "\n",
    "    table_sd = [['barabasi-albert', 3*np.std(properties_ba[0,:])/np.sqrt(runs), 3*np.std(properties_ba[1,:])/np.sqrt(runs), 3*np.std(properties_ba[2,:])/np.sqrt(runs), 3*np.std(properties_ba[3,:]/np.sqrt(runs))],\n",
    "            ['watts-strogatz', 3*np.std(properties_ws[0,:])/np.sqrt(runs), 3*np.std(properties_ws[1,:])/np.sqrt(runs), 3*np.std(properties_ws[2,:])/np.sqrt(runs), 3*np.std(properties_ws[3,:]/np.sqrt(runs))], \n",
    "            ['erdos-renyi', 3*np.std(properties_er[0,:])/np.sqrt(runs), 3*np.std(properties_er[1,:])/np.sqrt(runs), 3*np.std(properties_er[2,:])/np.sqrt(runs), 3*np.std(properties_er[3,:])/np.sqrt(runs)]]\n",
    "\n",
    "    table = [['barabasi-albert', np.mean(properties_ba[0,:]), np.mean(properties_ba[1,:]), np.mean(properties_ba[2,:]), np.mean(properties_ba[3,:])],\n",
    "            ['watts-strogatz', np.mean(properties_ws[0,:]), np.mean(properties_ws[1,:]), np.mean(properties_ws[2,:]), np.mean(properties_ws[3,:])], \n",
    "            ['erdos-renyi', np.mean(properties_er[0,:]), np.mean(properties_er[1,:]), np.mean(properties_er[2,:]), np.mean(properties_er[3,:])]]\n",
    "\n",
    "    print(f'\\n 3\\u03C3 for n={n} nodes')\n",
    "    print(tabulate(table_sd, headers=['clustering_coefficient', 'closeness_centrality', 'betweenness_centrality', 'degree_centrality']))\n",
    "\n",
    "    print(f'\\n properties for n={n} nodes')\n",
    "    print(tabulate(table, headers=['clustering_coefficient', 'closeness_centrality', 'betweenness_centrality', 'degree_centrality']))\n",
    "\n",
    "    return (er_list, ws_list, ba_list)\n",
    "\n",
    "er_list_50, ws_list_50, ba_list_50 = give_networks(50)\n",
    "er_list, ws_list, ba_list = give_networks(100) ### Saving for next experiment\n",
    "er_list_200, ws_list_200, ba_list_200 = give_networks(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate SIR spread on the network\n",
    "plt.clf()\n",
    "beta_list =  [1, 1/3, 1/6] \n",
    "gamma = 1/3\n",
    "I0 = 0.01\n",
    "n_iterations = 30\n",
    "n_samples=100\n",
    "\n",
    "for beta in beta_list:\n",
    "    # First create empty lists to store values for X, Y and Z\n",
    "    er_X, er_Y, er_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "    ws_X, ws_Y, ws_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "    ba_X, ba_Y, ba_Z = [0]*n_iterations, [0]*n_iterations, [0]*n_iterations\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        er = er_list[i]\n",
    "        ws = ws_list[i]\n",
    "        ba = ba_list[i]\n",
    "\n",
    "        trends_er = evaluate(beta, gamma, I0, n_iterations, er)\n",
    "        trends_ws = evaluate(beta, gamma, I0, n_iterations, ws)\n",
    "        trends_ba = evaluate(beta, gamma, I0, n_iterations, ba)\n",
    "\n",
    "        # Add values of i-th evaluation to the matrix\n",
    "        er_X = np.add(er_X, trends_er[0]['trends']['node_count'][0])\n",
    "        er_Y = np.add(er_Y, trends_er[0]['trends']['node_count'][1])\n",
    "        er_Z = np.add(er_Z, trends_er[0]['trends']['node_count'][2])\n",
    "\n",
    "        ws_X = np.add(ws_X, trends_ws[0]['trends']['node_count'][0]) \n",
    "        ws_Y = np.add(ws_Y, trends_ws[0]['trends']['node_count'][1]) \n",
    "        ws_Z = np.add(ws_Z, trends_ws[0]['trends']['node_count'][2]) \n",
    "\n",
    "        ba_X = np.add(ba_X, trends_ba[0]['trends']['node_count'][0]) \n",
    "        ba_Y = np.add(ba_Y, trends_ba[0]['trends']['node_count'][1]) \n",
    "        ba_Z = np.add(ba_Z, trends_ba[0]['trends']['node_count'][2]) \n",
    "\n",
    "    # Normalize number of hosts by deviding by number of samples and number of nodes (100)\n",
    "    er_I = er_Y/(100*n_samples)\n",
    "    ws_I = ws_Y/(100*n_samples)\n",
    "    ba_I = ba_Y/(100*n_samples)\n",
    "\n",
    "    plt.figure(figsize=(10,6), tight_layout=True)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    \n",
    "    plt.plot(er_I, label=\"Erd\\u0151s-R\\u00e9nyi\", linewidth=2)\n",
    "    plt.plot(ws_I, label=\"Watts-Strogatz\", linewidth=2)\n",
    "    plt.plot(ba_I, label=\"Barab\\u00e1si-Albert\", linewidth=2)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel('t', fontsize = 25)\n",
    "    plt.ylabel('I', fontsize = 25)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.title(f'Fraction of infected hosts over time', fontsize=25)\n",
    "    plt.legend(fontsize = 24)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.savefig(f'plots2/beta-{np.round(beta,2)}_gamma-{np.round(gamma,2)}_I0-{I0}.png')\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic vaccination campaign\n",
    "\n",
    "def evaluate_vacc_step(beta, gamma, infected_nodes, n_iterations, G, test_accuracy=1, tests_used=0, n_vacc=0, test_max=200):\n",
    "    model = ep.SIRModel(G) \n",
    "\n",
    "    # Test if there are infected nodes and if there are any tests left to use\n",
    "    if len(infected_nodes) != 0 and tests_used < test_max:\n",
    "        for _ in range(n_vacc):\n",
    "            # Look for nodes with highest closeness centrality\n",
    "            closeness_centrality = nx.closeness_centrality(G)\n",
    "            closeness_centrality_values = list(closeness_centrality.values())\n",
    "            closeness_centrality_ordered = sorted(list(closeness_centrality.values()), reverse=True)\n",
    "\n",
    "            infected = True\n",
    "            next_max = 0\n",
    "\n",
    "            # Keep looking for a node to vaccinate until one is found or all nodes have been looked into\n",
    "            while infected == True and next_max < len(closeness_centrality_ordered):\n",
    "                accuracy = np.random.binomial(1, test_accuracy)\n",
    "                target_index = closeness_centrality_values.index(closeness_centrality_ordered[next_max])\n",
    "                target_node = list(closeness_centrality.keys())[target_index]\n",
    "                tests_used += 1\n",
    "                next_max += 1\n",
    "\n",
    "                # In case of a false negative, the vaccination is \"thrown out\"\n",
    "                if target_node in infected_nodes and accuracy == 0:\n",
    "                    infected = False\n",
    "                \n",
    "                # In case a suscpetible is found and not all tests have been used yet, the node is removed from the system\n",
    "                if target_node not in infected_nodes and accuracy == 1 and tests_used < test_max:\n",
    "                    G.remove_node(target_node)\n",
    "                    infected = False\n",
    "                \n",
    "    for _ in range(n_iterations):\n",
    "        # Model Configuration\n",
    "        cfg = mc.Configuration()\n",
    "        cfg.add_model_parameter('beta', beta)\n",
    "        cfg.add_model_parameter('gamma', gamma)\n",
    "        cfg.add_model_initial_configuration(\"Infected\", infected_nodes)\n",
    "\n",
    "        model.set_initial_status(cfg)\n",
    "\n",
    "        # Simulation execution\n",
    "        iterations = model.iteration_bunch(1)\n",
    "        trends = model.build_trends(iterations)\n",
    "\n",
    "        # Find direct neighbors of infected nodes\n",
    "        neighbors_infected_nodes = []\n",
    "        for node in infected_nodes:\n",
    "            for neighbor_node in G.neighbors(node):\n",
    "                neighbors_infected_nodes.append(neighbor_node)\n",
    "\n",
    "            # Remove neighbor if neighbor already infected\n",
    "            overlap = np.intersect1d(neighbors_infected_nodes, infected_nodes)\n",
    "            for node in overlap:\n",
    "                neighbors_infected_nodes.remove(node)\n",
    "            \n",
    "            # Only have each neighbour once, even if it is shared by multiple nodes\n",
    "            neighbors_infected_nodes = list(np.unique(neighbors_infected_nodes))\n",
    "\n",
    "        number_of_infections = trends[0]['trends']['status_delta'][1][0]\n",
    "        \n",
    "        if number_of_infections > 0:\n",
    "            \"\"\"Random neighbors of the infected nodes are now infected, if the simulation asks for more infections than\n",
    "            there are direct neighbors all direct neighbors will be infected\"\"\"\n",
    "            if len(neighbors_infected_nodes) > number_of_infections:\n",
    "                added_infections = np.random.choice(neighbors_infected_nodes, number_of_infections, replace=False)\n",
    "            else:\n",
    "                added_infections = np.random.choice(neighbors_infected_nodes, len(neighbors_infected_nodes), replace=False)\n",
    "            \n",
    "            infected_nodes.extend(added_infections)\n",
    "        \n",
    "        if number_of_infections < 0:\n",
    "            \"\"\"Random infected nodes are now recovered, if the simulation asks for more recovering infected hosts than\n",
    "            there are infected hosts all infected hosts will recover\"\"\"\n",
    "            if len(infected_nodes) > np.abs(number_of_infections):\n",
    "                removed_infections = np.random.choice(infected_nodes, np.abs(number_of_infections), replace=False)\n",
    "            else:\n",
    "                removed_infections = np.random.choice(infected_nodes, len(infected_nodes), replace=False)\n",
    "\n",
    "            for removed_infection in removed_infections:\n",
    "                infected_nodes.remove(removed_infection)\n",
    "                G.remove_node(removed_infection)\n",
    "                recovered_nodes.append(removed_infection)\n",
    "\n",
    "    return G, infected_nodes, recovered_nodes, tests_used\n",
    "    \n",
    "\n",
    "\"Creating edgelist\"\n",
    "data = np.loadtxt(open(\"transmission_network.csv\", \"rb\"), delimiter=\";\", skiprows=1)[:, 1:]\n",
    "nonzero_x = np.nonzero(data)[0]\n",
    "nonzero_y = np.nonzero(data)[1]\n",
    "\n",
    "edges=[]\n",
    "for i in range(len(nonzero_x)):\n",
    "    edges.append((nonzero_x[i], nonzero_y[i]))\n",
    "\n",
    "\"Set parameters\"\n",
    "beta =  1\n",
    "gamma = 1/3\n",
    "n_iterations = 2\n",
    "n_vacc_list = [1,3,5,10]\n",
    "test_accuracy_list=[0.5,0.75,1]\n",
    "\n",
    "n_samples=1000\n",
    "end_time={}\n",
    "max_infected={}\n",
    "end_time_std={}\n",
    "max_infected_std={}\n",
    "\n",
    "for test_accuracy in test_accuracy_list:\n",
    "    for n_vacc in n_vacc_list:\n",
    "        end_time_list, max_infected_list = [], []\n",
    "        end_time_list_std, max_infected_list_std = [], []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            G = nx.from_edgelist(edges)\n",
    "            # Randomly select 5 nodes which are infected\n",
    "            infected_nodes =  list(np.random.choice(list(G.nodes), 5, replace=False))\n",
    "            tests_used = 0\n",
    "            max_infected_nodes = 0 \n",
    "            t = -1 ### Start at t=0\n",
    "            test_max = 200\n",
    "\n",
    "            # Run  simulation until there are no infected nodes left\n",
    "            while len(infected_nodes) != 0:\n",
    "                t+=1\n",
    "                G_new, infected_nodes_new, recovered_nodes, tests_used_new = evaluate_vacc_step(beta, gamma, infected_nodes, n_iterations, G, test_accuracy, tests_used, n_vacc, test_max)\n",
    "                G=G_new\n",
    "                infected_nodes=infected_nodes\n",
    "                tests_used = tests_used_new\n",
    "\n",
    "                if len(infected_nodes) > max_infected_nodes:\n",
    "                    max_infected_nodes = len(infected_nodes)\n",
    "                    \n",
    "            end_time_list.append(t)\n",
    "            max_infected_list.append(max_infected_nodes)\n",
    "\n",
    "        end_time[test_accuracy, n_vacc] = np.mean(end_time_list)\n",
    "        max_infected[test_accuracy, n_vacc] = np.mean(max_infected_list)\n",
    "\n",
    "        end_time_std[test_accuracy, n_vacc] = np.std(end_time_list) / np.sqrt(n_samples)\n",
    "        max_infected_std[test_accuracy, n_vacc] = np.mean(max_infected_list) / np.sqrt(n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time until the disease passes 74.065 0.9362344658257353\n",
      "Average maximum number of infected hosts 267.192 0.6372944562759039\n"
     ]
    }
   ],
   "source": [
    "### Below a modified version of the code above is given where test_max = n_vacc = 0 and thus no tests or vaccinations will be performed\n",
    "\n",
    "end_time_value_list = []\n",
    "max_infected_nodes_list = []\n",
    "n_samples = 1000\n",
    "\n",
    "for _ in range(n_samples):\n",
    "    G = nx.from_edgelist(edges)\n",
    "    infected_nodes =  list(np.random.choice(list(G.nodes), 5, replace=False))\n",
    "    tests_used = 0\n",
    "    t = -1 ### Start at t=0\n",
    "    test_max = 0\n",
    "    n_vacc = 0\n",
    "    max_infected_nodes = 0\n",
    "    while len(infected_nodes) != 0:\n",
    "        t+=1\n",
    "        G_new, infected_nodes_new, recovered_nodes, tests_used_new = evaluate_vacc_step(beta, gamma, infected_nodes, n_iterations, G, test_accuracy, tests_used, n_vacc, test_max)\n",
    "        G=G_new\n",
    "        infected_nodes=infected_nodes\n",
    "        tests_used = tests_used_new\n",
    "\n",
    "        if len(infected_nodes) > max_infected_nodes:\n",
    "            max_infected_nodes = len(infected_nodes)\n",
    "\n",
    "    end_time_value_list.append(t)\n",
    "    max_infected_nodes_list.append(max_infected_nodes)\n",
    "\n",
    "print('Average time until the disease passes', np.mean(end_time_value_list), 3*np.std(end_time_value_list)/np.sqrt(n_samples))\n",
    "print('Average maximum number of infected hosts', np.mean(max_infected_nodes_list), 3*np.std(max_infected_nodes_list)/np.sqrt(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time until the disease passes\n",
      "           1       3       5      10\n",
      "----  ------  ------  ------  ------\n",
      "0.5   68.984  73.703  73.289  72.622\n",
      "0.75  68.881  73.298  72.922  72.269\n",
      "1     70.36   71.169  70.602  69.418\n",
      "3σ on endtime\n",
      "             1         3         5        10\n",
      "----  --------  --------  --------  --------\n",
      "0.5   0.856487  1.011     0.948064  0.982128\n",
      "0.75  1.03412   0.952901  1.0044    0.977414\n",
      "1     0.912781  0.945235  0.979644  0.990706\n"
     ]
    }
   ],
   "source": [
    "table = [[test_accuracy_list[0], end_time[test_accuracy_list[0], n_vacc_list[0]], end_time[test_accuracy_list[0], n_vacc_list[1]], end_time[test_accuracy_list[0], n_vacc_list[2]], end_time[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], end_time[test_accuracy_list[1], n_vacc_list[0]], end_time[test_accuracy_list[1], n_vacc_list[1]], end_time[test_accuracy_list[1], n_vacc_list[2]], end_time[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], end_time[test_accuracy_list[2], n_vacc_list[0]],end_time[test_accuracy_list[2], n_vacc_list[1]], end_time[test_accuracy_list[2], n_vacc_list[2]], end_time[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "table_std = [[test_accuracy_list[0], 3*end_time_std[test_accuracy_list[0], n_vacc_list[0]], 3*end_time_std[test_accuracy_list[0], n_vacc_list[1]], 3*end_time_std[test_accuracy_list[0], n_vacc_list[2]], 3*end_time_std[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], 3*end_time_std[test_accuracy_list[1], n_vacc_list[0]], 3*end_time_std[test_accuracy_list[1], n_vacc_list[1]], 3*end_time_std[test_accuracy_list[1], n_vacc_list[2]], 3*end_time_std[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], 3*end_time_std[test_accuracy_list[2], n_vacc_list[0]],3*end_time_std[test_accuracy_list[2], n_vacc_list[1]], 3*end_time_std[test_accuracy_list[2], n_vacc_list[2]], 3*end_time_std[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "print('Average time until the disease passes')\n",
    "print(tabulate(table, headers=n_vacc_list))\n",
    "\n",
    "print('3\\u03C3 on endtime')\n",
    "print(tabulate(table_std, headers=n_vacc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average maximum number of infected hosts\n",
      "            1        3        5       10\n",
      "----  -------  -------  -------  -------\n",
      "0.5   264.007  257.499  251.238  238.924\n",
      "0.75  263.473  255.546  247.837  235.449\n",
      "1     261.686  250.25   239.283  221.64\n",
      "3σ on max infected\n",
      "            1        3        5       10\n",
      "----  -------  -------  -------  -------\n",
      "0.5   25.0459  24.4285  23.8345  22.6663\n",
      "0.75  24.9952  24.2432  23.5119  22.3367\n",
      "1     24.8257  23.7408  22.7004  21.0266\n"
     ]
    }
   ],
   "source": [
    "table = [[test_accuracy_list[0], max_infected[test_accuracy_list[0], n_vacc_list[0]], max_infected[test_accuracy_list[0], n_vacc_list[1]], max_infected[test_accuracy_list[0], n_vacc_list[2]], max_infected[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], max_infected[test_accuracy_list[1], n_vacc_list[0]], max_infected[test_accuracy_list[1], n_vacc_list[1]], max_infected[test_accuracy_list[1], n_vacc_list[2]], max_infected[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], max_infected[test_accuracy_list[2], n_vacc_list[0]],max_infected[test_accuracy_list[2], n_vacc_list[1]], max_infected[test_accuracy_list[2], n_vacc_list[2]], max_infected[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "table_std = [[test_accuracy_list[0], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[0]], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[1]], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[2]], 3*max_infected_std[test_accuracy_list[0], n_vacc_list[3]]],\n",
    "         [test_accuracy_list[1], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[0]], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[1]], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[2]], 3*max_infected_std[test_accuracy_list[1], n_vacc_list[3]]], \n",
    "         [test_accuracy_list[2], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[0]], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[1]], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[2]], 3*max_infected_std[test_accuracy_list[2], n_vacc_list[3]]]]\n",
    "\n",
    "print('Average maximum number of infected hosts')\n",
    "print(tabulate(table, headers=n_vacc_list))\n",
    "\n",
    "print('3\\u03C3 on max infected')\n",
    "print(tabulate(table_std, headers=n_vacc_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
